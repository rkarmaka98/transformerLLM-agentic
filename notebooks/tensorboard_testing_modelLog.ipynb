{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef5efab",
   "metadata": {},
   "source": [
    "# Visualizing Models, Data and Training with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b62db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2c7c6",
   "metadata": {},
   "source": [
    "Transformations are preprocessing pipeline that every image passes through before going through training or inference.\n",
    "The model expects tensors not raw image arrays and normalization helps in gradients flow better. Data augmentations through transformation make model more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f738f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformations for the dataset by stacking a chain of preprocessing steps\n",
    "# each image will go through these steps before being fed to the model\n",
    "transform = transforms.Compose(\n",
    "    # Convert PIL Image [0,255] or numpy.ndarray to Pytorch tensor [0,1]\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize tensor with mean(0.5) and std deviation(0.5) to range [-1,1]\n",
    "        # Keeps input centered around 0 and helps optimization (gradient descent) converge faster\n",
    "        # Prevents one feature (pixel brightness) from dominating others\n",
    "        # works better with activation functions like tanh, sigmoid\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fbb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, train=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, train=False, transform=transform\n",
    ")\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dad4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = (\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle Boot\",\n",
    ")\n",
    "\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07224138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convs to extract features (edges, shapes, textures).\n",
    "# Pooling to reduce spatial size while keeping important info.\n",
    "# FC layers to make final classification decisions.\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input channel 1 (grayscale), output 6 channels enough to capture basic features\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # Half the spatial dimensions keeps strongest features, reduces computation\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Before going into fully connected layers, flatten the 3D tensor to 1D, -1 infers batch size\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        # RELU adds non-linearity, helps model learn complex patterns\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bf48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3db5d9",
   "metadata": {},
   "source": [
    "# Writing into Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# SummaryWriter is our key object for writing information to Tensorboard\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(\"runs/fashion_mnist_experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99099ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Makes an iterator object out of the dataloader object\n",
    "dataiter = iter(trainloader)\n",
    "# gives the next batch of images and labels (4 each bc batch_size=4)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image(\"four_fashion_mnist_images\", img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2fbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model graph to tensorboard\n",
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# The purpose of this code is to select a random subset of images and their corresponding labels from\n",
    "# the training dataset, reshape the images into flat feature vectors, and then log these embeddings to\n",
    "# Tensorboard. This allows visualization of how the images are arranged in the high-dimensional feature space.\n",
    "#\n",
    "# The function select_n_random randomly picks n datapoints (and their labels) from the dataset.\n",
    "def select_n_random(data, labels, n=100):\n",
    "    \"\"\"\n",
    "    Selects n random datapoints and their corresponding labels from a dataset.\n",
    "\n",
    "    The function first creates a random permutation of the indices, then selects the first n datapoints.\n",
    "    This helps in visualizing a diverse subset of the dataset in Tensorboard.\n",
    "    \"\"\"\n",
    "    assert len(data) == len(labels)\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "\n",
    "# Select a random subset of images and labels from the training dataset\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# Convert label indices to their actual class names using the `classes` tuple.\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# Reshape the images into feature vectors (flattening each 28x28 image into a 784-dimensional vector)\n",
    "features = images.view(-1, 28 * 28)\n",
    "\n",
    "# Log the embeddings to Tensorboard. For each image, we record its flattened feature vector,\n",
    "# its class (metadata), and the original image (as label_img) for context.\n",
    "writer.add_embedding(features, metadata=class_labels, label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82134c11",
   "metadata": {},
   "source": [
    "The function images_to_probs computes the network’s predictions on a batch of images and returns both the predicted class indices and their corresponding probabilities (using softmax on the logits). The function plot_classes_preds uses images_to_probs to obtain predictions and probabilities, then shows a grid of images with the predicted and true labels annotated, coloring predictions in green if they match and in red if they don’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    \"\"\"\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    \"\"\"\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    \"\"\"\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    \"\"\"\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx + 1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\n",
    "            \"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "                classes[preds[idx]], probs[idx] * 100.0, classes[labels[idx]]\n",
    "            ),\n",
    "            color=(\"green\" if preds[idx] == labels[idx].item() else \"red\"),\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fc3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:  # every 1000 mini-batches...\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar(\n",
    "                \"training loss\", running_loss / 1000, epoch * len(trainloader) + i\n",
    "            )\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure(\n",
    "                \"predictions vs. actuals\",\n",
    "                plot_classes_preds(net, inputs, labels),\n",
    "                global_step=epoch * len(trainloader) + i,\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    \"\"\"\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    \"\"\"\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(\n",
    "        classes[class_index],\n",
    "        tensorboard_truth,\n",
    "        tensorboard_probs,\n",
    "        global_step=global_step,\n",
    "    )\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
